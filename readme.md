# Network System Administration Project: Automated CI/CD for Dockerized Web App on AWS EC2

## üöÄ Project Overview

This project demonstrates a robust and automated Continuous Integration/Continuous Deployment (CI/CD) pipeline for deploying a simple, static Nginx web application. The entire infrastructure provisioning, server configuration, and application deployment are orchestrated using a suite of modern DevOps tools, ensuring a seamless, repeatable, and efficient delivery process from code commit to a live web server on AWS EC2.

**Key Technologies Used:**

- **Cloud Provider:** AWS (Amazon Web Services)
- **Infrastructure as Code (IaC):** Terraform (v1.8.0)
- **Configuration Management & Deployment:** Ansible (v2.9+)
- **Containerization:** Docker & Docker Compose (v3.8)
- **CI/CD Orchestration:** GitHub Actions
- **Version Control:** Git & GitHub

## üìÅ Project Structure

Our project is organized to keep things clean and manageable. Here's a quick look at the main directories and their contents:

Here is a comprehensive and detailed README.md file, updated with explanations and specifics directly from the files we provided (playbook.yml, nginx.conf, docker-compose.yml, main.yml, hosts.ini, terraform-main.tf, terraform-variables.tf, and terraform-versions.tf).

This README.md is designed to be placed at the root of my GitHub repository and will serve as the primary documentation for my project.

Markdown

# Network System Administration Project: Automated CI/CD for Dockerized Web App on AWS EC2

## üöÄ Project Overview

This project demonstrates a robust and automated Continuous Integration/Continuous Deployment (CI/CD) pipeline for deploying a simple, static Nginx web application. The entire infrastructure provisioning, server configuration, and application deployment are orchestrated using a suite of modern DevOps tools, ensuring a seamless, repeatable, and efficient delivery process from code commit to a live web server on AWS EC2.

**Key Technologies Used:**

- **Cloud Provider:** AWS (Amazon Web Services)
- **Infrastructure as Code (IaC):** Terraform (v1.8.0)
- **Configuration Management & Deployment:** Ansible (v2.9+)
- **Containerization:** Docker & Docker Compose (v3.8)
- **CI/CD Orchestration:** GitHub Actions\* **Version Control:** Git & GitHub

## üìÅ Project Structure

Our project is organized to keep things clean and manageable. Here's a quick look at the main directories and their contents:

```
.
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ main.yml                  # GitHub Actions CI/CD pipeline definition
‚îú‚îÄ‚îÄ DeployTools/
‚îÇ   ‚îú‚îÄ‚îÄ ansible/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ host.ini              # Ansible dynamic inventory file (generated by CI/CD)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ playbook.yml              # Ansible playbook for server config & app deployment
‚îÇ   ‚îî‚îÄ‚îÄ terraform/
‚îÇ       ‚îú‚îÄ‚îÄ main.tf                   # Defines AWS VPC, Subnet, IGW, Route Table, Security Group, EC2 instance, and SSH key handling.
‚îÇ       ‚îú‚îÄ‚îÄ variables.tf              # Input variables for Terraform configuration.
‚îÇ       ‚îú‚îÄ‚îÄ outputs.tf                # Defines outputs from Terraform (e.g., EC2 Public IP).
‚îÇ       ‚îî‚îÄ‚îÄ versions.tf               # Specifies required Terraform and provider versions.
‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.nginx              # Dockerfile to build the Nginx web app image.
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf                    # Custom Nginx configuration for the web server.
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ index.html                    # Sample static web content (my web page).
‚îú‚îÄ‚îÄ docker-compose.yml                # Defines Docker services for the web application (Nginx web).
‚îî‚îÄ‚îÄ README.md                         # This file!

```

---

## üìã Prerequisites

Before we get started, make sure we have the following in place:

1.  **AWS Account:** An active AWS account with programmatic access (Access Key ID and Secret Access Key).
2.  **AWS IAM User:** An IAM user with sufficient permissions to create/manage EC2 instances, Security Groups, VPC resources, S3 buckets (for Terraform state backend), and DynamoDB tables (for Terraform state locking).
3.  **Docker Hub Account:** An account on Docker Hub to store my Docker images.
4.  **GitHub Account:** A GitHub account to host my repository and run GitHub Actions.
5.  **An Existing AWS EC2 Key Pair:** A pre-existing EC2 Key Pair in my AWS account named `my-ec2-keypair` in the `eu-north-1` region. The private key corresponding to this public key will need to be provided to GitHub Actions as a secret.
6.  **Local Tools (for local testing/development - CI/CD handles deployment):**
    - Git
    - Docker Desktop (or Docker Engine & Docker Compose)
    - Terraform CLI (v1.0.0+)
    - Ansible (v2.9+)
    - Python 3 & pip

## ‚öôÔ∏è Setup and Configuration

This project is primarily designed for automated deployment via GitHub Actions. However, understanding the underlying configurations is key.

### 1. AWS Credentials

**Important:** my AWS credentials **must not** be hardcoded into my repository. They should be securely stored as GitHub Secrets.

- In my GitHub repository, go to `Settings` > `Secrets and variables` > `Actions` > `New repository secret`.
- Add the following secrets:
  - `AWS_ACCESS_KEY_ID`: my AWS IAM user access key.
  - `AWS_SECRET_ACCESS_KEY`: my AWS IAM user secret access key.
  - `SSH_PRIVATE_KEY`: The private key associated with my AWS EC2 key pair (`my-ec2-keypair`). This key is crucial for Ansible to connect to the EC2 instance. **Ensure this key is correctly formatted; for multi-line keys, it's best to paste it as is, or base64 encode it if issues arise.**

### 2. Docker Hub Credentials

Similar to AWS, my Docker Hub credentials should be stored securely:

- In my GitHub repository, go to `Settings` > `Secrets and variables` > `Actions` > `New repository secret`.
- Add the following secrets:
  - `DOCKER_USERNAME`: my Docker Hub username.
  - `DOCKER_PASSWORD`: my Docker Hub password (or a personal access token for enhanced security).

### 3. Terraform Configuration (`DeployTools/terraform/`)

Terraform is used to provision my AWS infrastructure.

- **`main.tf`**:
  - Defines an AWS VPC (`10.0.0.0/16`) and a public subnet (`10.0.1.0/24`) with an Internet Gateway for internet access.
  - Sets up a Security Group (`${var.environment}-web-server-sg`) to allow inbound SSH (Port 22) and HTTP (Port 80) traffic from anywhere (`0.0.0.0/0`).
  - References an **existing AWS EC2 Key Pair** named `my-ec2-keypair` using `data "aws_key_pair"`. The corresponding private key is expected to be provided as `SSH_PRIVATE_KEY` GitHub Secret.
  - Provisions an AWS EC2 instance (`${var.environment}-web-server`) in the public subnet, associating a public IP.
  - Includes a `user_data` script (intended for initial setup) within the EC2 instance definition. **Note:** The current `user_data` script uses `yum` and `amazon-linux-extras`, which are for Amazon Linux. However, my `ami_id` in `variables.tf` specifies an Ubuntu 24.04 AMI, and Ansible expects an `ubuntu` user with `apt`. For proper initial setup on Ubuntu, the `user_data` should be adjusted to use `apt` commands (e.g., `sudo apt-get update -y && sudo apt-get install -y docker.io`).
  - Configures an S3 backend for Terraform state management:
    ```hcl
    backend "s3" {
      bucket         = "network-admin-ci-cd-bucket-1"  # <--- MUST match my manually created S3 bucket
      key            = "app-deployment/terraform.tfstate"
      region         = "eu-north-1"
      encrypt        = true
    }
    ```
    **Action Required:** we **must manually create an S3 bucket** named `network-admin-ci-cd-bucket-1` in the `eu-north-1` region before running the pipeline for the first time. It is highly recommended to enable **versioning** on this S3 bucket for state history and recovery. If we plan to use state locking, we'd also need a DynamoDB table named `terraform-lock` (with `LockID` as a primary key) but we skiped this part.
- **`variables.tf`**:
  - `aws_region`: `eu-north-1`
  - `instance_type`: `t3.micro` (free tier eligible)
  - `ami_id`: `ami-042b4708b1d05f512` (Canonical, Ubuntu, 24.04, amd64 noble image).
  - `key_pair_name`: `my-ec2-keypair`
  - `environment`: `development`
- **`outputs.tf`**: (Implicitly mentioned in `main.yml` when retrieving `vm_public_ip`). This file typically defines what values Terraform should output after an apply, in this case, the public IP of the EC2 instance.
- **`versions.tf`**:
  - Specifies required Terraform version `>= 1.0.0`.
  - Defines required providers and their versions: `aws (~> 5.0)`, `tls (~> 4.0)` (for SSH key generation, though not directly used for EC2 in `main.tf`), and `local (~> 2.0)` (for writing private key to local file, also not used in CI/CD).

### 4. Ansible Playbook (`DeployTools/ansible/playbook.yml`)

This `playbook.yml` is the heart of the configuration management for the EC2 instance. It performs the following tasks:

- Updates all `apt` packages on the Ubuntu EC2 instance.
- Installs `docker.io` and `docker-compose` (v1).
- Starts and enables the Docker service.
- Adds the `ubuntu` user to the `docker` group, allowing Docker commands without `sudo`.
- Creates the application deployment directory `/opt/network-systemadmin-app`.
- Copies the entire project context (excluding `.git/`, `DeployTools/`, `.vscode/`, `__pycache__/`, `*.swp`, `*.bak`) from the GitHub Actions runner to the EC2 instance's `app_project_dir`.
- Ensures correct ownership (`ubuntu:ubuntu`) and permissions (`0755`) for all copied files.
- Stops and removes any previously running Docker Compose services (`docker-compose down -v`) (with `ignore_errors` for first runs).
- Builds (if necessary) and runs the Docker Compose services in detached mode (`docker-compose up -d --build --force-recreate`), starting the Nginx web application.
- Displays the Docker Compose deployment output for debugging.

**Note:** The `DeployTools/ansible/inventory/host.ini` file we provided is an example for local manual execution. In the CI/CD pipeline, this file is dynamically generated by the `ansible-deploy` job in `main.yml` to ensure it points to the correct, newly provisioned EC2 instance.

### 5. Docker Configuration (`nginx/Dockerfile.nginx` & `docker-compose.yml`)

- **`nginx/Dockerfile.nginx`**: This Dockerfile defines the instructions for building my Nginx web server image.
  - It starts from a lean `nginx:alpine` base image.
  - Copies my custom `nginx.conf` into the container.
  - Copies my static web content from the `public/` directory into Nginx's default web serving path (`/usr/share/nginx/html`) inside the container.
- **`docker-compose.yml`**: This file defines the `web` service for my application.
  - Uses `version: '3.8'`.
  - The `web` service's image is built from the `nginx/Dockerfile.nginx` relative to the project root.
  - Sets a `container_name` of `network-systemadmin-app`.
  - Maps port 80 on the host machine to port 80 inside the container (`"80:80"`), making my web app accessible.
  - Configures `restart: always` to ensure the container automatically restarts if it stops.

### 6. GitHub Actions Workflow (`.github/workflows/main.yml`)

This `main.yml` file orchestrates the entire CI/CD pipeline, triggered on `push` to the `main` branch or `workflow_dispatch` (manual trigger). It defines three sequential jobs:

- **`build-and-push-docker`** (Continuous Integration)
  - **Purpose:** Builds the Docker image for the Nginx web app and pushes it to Docker Hub.
  - **Steps:** Checks out the repository, sets up Docker Buildx, logs into Docker Hub using secrets (`DOCKER_USERNAME`, `DOCKER_PASSWORD`), and then builds and pushes the image with the tag `mohibulhasan/network-systemadmin-ca-01-web:1.0`.
- **`terraform-apply`** (Infrastructure Provisioning - Continuous Deployment)
  - **Dependencies:** Runs only after `build-and-push-docker` successfully completes.
  - **Purpose:** Provisions or updates the AWS EC2 infrastructure using Terraform.
  - **Steps:** Checks out the repository, sets up Terraform CLI (v1.8.0), configures AWS credentials using secrets (`AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`) and the `AWS_REGION` environment variable (`eu-north-1`). It then runs `terraform init` (connecting to S3 backend), `terraform validate`, and `terraform apply -auto-approve`.
  - **Outputs:** Crucially, this job retrieves the `vm_public_ip` from Terraform's output and makes it available for subsequent jobs.
- **`ansible-deploy`** (Application Deployment - Continuous Deployment)
  - **Dependencies:** Runs only after `terraform-apply` successfully completes, using its `vm_public_ip` output.
  - **Purpose:** Connects to the provisioned EC2 instance via SSH and deploys the Dockerized web application using Ansible.
  - **Steps:** Checks out the repository, installs Ansible and the `docker` Python module. It then sets up the SSH key (`SSH_PRIVATE_KEY` secret) on the runner, adds the EC2 host to `known_hosts`, dynamically creates the Ansible inventory file (`DeployTools/ansible/inventory/host.ini`) pointing to the EC2's public IP, and finally executes the `ansible-playbook -i inventory/host.ini playbook.yml`.

## üöÄ CI/CD Pipeline Flow

1.  **Code Push:** A developer pushes code changes to the `main` branch of the GitHub repository.
2.  **CI Trigger:** GitHub Actions detects the push and triggers the `main.yml` workflow.
3.  **Build & Push Docker Image (`build-and-push-docker` job):**
    - The latest application code is pulled.
    - A new Docker image is built based on `nginx/Dockerfile.nginx`.
    - The newly built image is tagged (e.g., `mohibulhasan/network-systemadmin-ca-01-web:1.0`) and pushed to Docker Hub.
4.  **Provision Infrastructure (`terraform-apply` job):**
    - Once the Docker image is successfully pushed, this job begins.
    - Terraform initializes, reads the `DeployTools/terraform/` configuration, and connects to the S3 state backend.
    - Terraform applies the desired state, provisioning (or updating) the AWS EC2 instance, its associated Security Group, and ensuring network connectivity.
    - The public IP address of the EC2 instance is captured and passed as an output.
5.  **Deploy Application (`ansible-deploy` job):**
    - After the EC2 instance is ready, this job takes over.
    - Ansible connects to the newly provisioned EC2 instance using SSH and the provided private key.
    - It executes `DeployTools/ansible/playbook.yml`, which:
      - Installs Docker and Docker Compose on the EC2.
      - Copies the application source code (including `docker-compose.yml` and `nginx/` directory) to `/opt/network-systemadmin-app` on the EC2.
      - Runs `docker-compose up -d --build --force-recreate` to launch the web application container.
6.  **Application Live:** The web application is now accessible via the public IP address of the EC2 instance.

## ‚úÖ Verification

Once the `ansible-deploy` job successfully completes (all steps show a green checkmark):

1.  **Retrieve EC2 Public IP:** In the `terraform-apply` job logs, find the output for `vm_public_ip`. Alternatively, we can find the Public IPv4 address in my AWS EC2 console under "Instances".
2.  **Access Web Application:** Open my web browser and navigate to `http://<my_EC2_PUBLIC_IP>`. we should see the static Nginx web page served by my Docker container.

## üêõ Troubleshooting

- **GitHub Actions Failure:**
  - Always check the detailed logs for each job (`build-and-push-docker`, `terraform-apply`, `ansible-deploy`). The error messages are usually quite descriptive.
  - Common issues include: Incorrect GitHub Secrets, incorrect file paths in workflow/playbook, AWS permission errors, Docker Hub login issues, or network connectivity problems.
- **Terraform Issues:**
  - Locally run `terraform validate` in `DeployTools/terraform/` to catch syntax errors.
  - Ensure my S3 backend bucket (`network-admin-ci-cd-bucket-1`) exists in the correct region and is correctly configured in `main.tf`.
  - Verify my AWS IAM user has the necessary permissions for EC2, VPC, S3, and potentially DynamoDB.
  - **User Data Inconsistency:** As noted in `main.tf` explanation, ensure the `user_data` script matches my chosen AMI (Ubuntu in this case) and uses `apt` commands if we intend it to run (though Ansible will perform Docker setup later anyway).
- **Ansible Connection Issues:**
  - Verify that my `SSH_PRIVATE_KEY` secret is correctly formatted and has no extra spaces or newlines.
  - Ensure the EC2 Security Group (`${var.environment}-web-server-sg`) allows SSH (Port 22) traffic from the GitHub Actions runner's IP ranges (which are usually dynamic, so `0.0.0.0/0` in the SG is typical for CI/CD unless more advanced IP restrictions are in place).
  - Confirm the `ansible_user` (`ubuntu`) is correct for my Ubuntu AMI.
- **Application Not Accessible (HTTP 80):**
  - Check the EC2 Security Group inbound rules to ensure Port 80 is open to `0.0.0.0/0` (or my intended source IPs).
  - SSH into the EC2 instance (using my private key: `ssh -i ~/.ssh/id_ec2_ansible.pem ubuntu@<EC2_PUBLIC_IP>`) and run `sudo docker ps` to confirm the `network-systemadmin-app` container is running.
  - Check Docker container logs for errors: `sudo docker logs network-systemadmin-app`.

## ‚ú® Further Enhancements

This project provides a solid foundation. Here are some ideas for future improvements:

- **Blue/Green or Canary Deployments:** Implement more advanced deployment strategies for zero-downtime updates.
- **Monitoring & Alerting:** Integrate tools like Prometheus/Grafana or AWS CloudWatch for application and infrastructure monitoring.
- **Cost Optimization:** Implement autoscaling for EC2 instances based on load.
- **Database Integration:** Add a containerized database (e.g., PostgreSQL, MySQL) managed by Docker Compose.
- **Domain & SSL:** Set up a custom domain name with Route 53 and configure SSL/TLS (HTTPS) using AWS Certificate Manager and an Application Load Balancer.
- **Parameterization:** Make more variables configurable via GitHub Actions inputs or Terraform variables for greater flexibility.
- **Testing:** Add automated unit, integration, and end-to-end tests to the CI/CD pipeline.
- **Code Quality:** Integrate linters and static analysis tools into the CI process.
- **Terraform Modules:** Refactor Terraform code into reusable modules for better organization and reusability.
- **Ansible Roles:** Organize Ansible playbooks into roles for better reusability and structure.

---
